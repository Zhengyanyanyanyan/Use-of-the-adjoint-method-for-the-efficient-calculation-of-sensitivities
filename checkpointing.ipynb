{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17890a8d",
   "metadata": {},
   "source": [
    "# vjp jvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dafa4287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward mode gradient g_dot: 0.115555555\n",
      "Reverse mode gradients a_bar, b_bar, c_bar: 0.124444455 -0.035555556 0.026666671\n",
      "Left-hand side (Input Sensitivity Product): 0.11555556952953339\n",
      "Right-hand side (Output Sensitivity Product): 0.11555555462837219\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def output(a, b, c):\n",
    "    d = b + c\n",
    "    e = a * c\n",
    "    f = d + e\n",
    "    g = e / f\n",
    "    return g\n",
    "\n",
    "# Set the initial values for a, b, c\n",
    "a, b, c = 2.0, 3.0, 4.0  # Example values\n",
    "\n",
    "# Set the sensitivities (tangents) for a, b, c\n",
    "a_dot, b_dot, c_dot = 1.0, 1.0, 1.0  # Example sensitivities\n",
    "\n",
    "# Function to compute forward mode derivative of g with respect to a, b, c\n",
    "def compute_forward_gradient(a, b, c, a_dot, b_dot, c_dot):\n",
    "    # Wrap the function to use with jax.jvp\n",
    "    def func(inputs):\n",
    "        a, b, c = inputs\n",
    "        return output(a, b, c)\n",
    "\n",
    "    # Inputs and their perturbations\n",
    "    inputs = jnp.array([a, b, c])\n",
    "    tangents = jnp.array([a_dot, b_dot, c_dot])\n",
    "\n",
    "    # Compute the Jacobian-vector product\n",
    "    _, g_dot = jax.jvp(func, (inputs,), (tangents,))\n",
    "    return g_dot\n",
    "\n",
    "# Compute g_dot\n",
    "g_dot = compute_forward_gradient(a, b, c, a_dot, b_dot, c_dot)\n",
    "print(\"Forward mode gradient g_dot:\", g_dot)\n",
    "\n",
    "# Function to compute reverse mode gradient of a, b, c given g_bar\n",
    "def compute_reverse_gradient(a, b, c, g_bar):\n",
    "    # Wrap the function to use with jax.vjp\n",
    "    def func(a, b, c):\n",
    "        return output(a, b, c)\n",
    "    \n",
    "    # Get the function output and vjp function\n",
    "    g, vjp_fun = jax.vjp(func, a, b, c)\n",
    "\n",
    "    # Compute the vector-Jacobian product\n",
    "    a_bar, b_bar, c_bar = vjp_fun(g_bar)\n",
    "    return a_bar, b_bar, c_bar\n",
    "\n",
    "# Assume g_bar is given (the sensitivity of the loss with respect to g)\n",
    "g_bar = 1.0  # Example sensitivity of the loss with respect to g\n",
    "\n",
    "# Compute a_bar, b_bar, c_bar\n",
    "a_bar, b_bar, c_bar = compute_reverse_gradient(a, b, c, g_bar)\n",
    "print(\"Reverse mode gradients a_bar, b_bar, c_bar:\", a_bar, b_bar, c_bar)\n",
    "\n",
    "Thou\n",
    "# Calculate the dot products\n",
    "lhs = a_dot * a_bar + b_dot * b_bar + c_dot * c_bar\n",
    "rhs = g_dot * g_bar\n",
    "\n",
    "print(f\"Left-hand side (Input Sensitivity Product): {lhs}\")\n",
    "print(f\"Right-hand side (Output Sensitivity Product): {rhs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3651aba7",
   "metadata": {},
   "source": [
    "# checkpointing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbf70f6",
   "metadata": {},
   "source": [
    "## no checkpointing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f2cb20",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "   S_{t+1} = S_{t} \\exp{((r-\\frac{1}2{\\sigma}^2){\\delta}t +{\\sigma}{\\sqrt{\\delta}t}{\\phi})}\n",
    "\\end{equation*}\n",
    "\n",
    "where $\\phi \\sim N(0,1)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05381417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHS: 2.567828732334462\n",
      "RHS: 2.567828732334464\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "  \n",
    "\n",
    "def simulate_gbm(S0, mu, sigma, T, dt, key):\n",
    "    num_steps = int(T / dt)\n",
    "    increments = random.normal(key, (num_steps,)) * jnp.sqrt(dt)\n",
    "    time_steps = jnp.linspace(dt, T, num_steps)\n",
    "    log_path = (mu - 0.5 * sigma**2) * time_steps + sigma * increments.cumsum(axis=0)\n",
    "    S_path = S0 * jnp.exp(log_path)\n",
    "    return S_path[-1]\n",
    "\n",
    "def forward_mode_gbm(S0, mu, sigma, T, dt, key, a_dot, b_dot, c_dot):\n",
    "    gbm_func = lambda x: simulate_gbm(x[0], x[1], x[2], T, dt, key)\n",
    "    inputs = jnp.array([S0, mu, sigma])\n",
    "    tangents = jnp.array([a_dot, b_dot, c_dot])  # Change to calculate sensitivity w.r.t. each input\n",
    "    _, g_dot = jax.jvp(gbm_func, (inputs,), (tangents,))\n",
    "    return g_dot\n",
    "\n",
    "def reverse_mode_gbm(S0, mu, sigma, T, dt, key, g_bar):\n",
    "    def gbm_func(S0, mu, sigma):\n",
    "        return simulate_gbm(S0, mu, sigma, T, dt, key)\n",
    "    _, vjp_fun = jax.vjp(gbm_func, S0, mu, sigma)\n",
    "    g_bar = 1.0  # Sensitivity of the loss w.r.t. output\n",
    "    return vjp_fun(g_bar)\n",
    "\n",
    "S0, mu, sigma = 100.0, 0.05, 0.2\n",
    "T, dt = 1.0, 0.01\n",
    "key = random.PRNGKey(0)\n",
    "g_bar = 1.0\n",
    "a_dot, b_dot, c_dot = 1.0,1.0,1.0\n",
    "\n",
    "# Calculate forward and reverse mode derivatives\n",
    "g_dot = forward_mode_gbm(S0, mu, sigma, T, dt, key, a_dot, b_dot, c_dot)\n",
    "a_bar, b_bar, c_bar = reverse_mode_gbm(S0, mu, sigma, T, dt, key, g_bar)\n",
    "\n",
    "# Assume the forward and reverse are the same for demonstration\n",
    "lhs = sum(jnp.array([a_dot, b_dot, c_dot]) * jnp.array([a_bar, b_bar, c_bar]))\n",
    "rhs = g_dot * g_bar  # g_bar assumed to be same as g_dot for simplicity\n",
    "\n",
    "print(\"LHS:\", lhs)\n",
    "print(\"RHS:\", rhs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b850db",
   "metadata": {},
   "source": [
    "another approximation\n",
    "\\begin{equation*}\n",
    "   S_{t+1} = S_{t} (1+r{\\delta}t+{\\sigma}{\\phi}{\\sqrt{\\delta t}})\n",
    "\\end{equation*}\n",
    "since we have $dW \\sim {\\phi}{\\sqrt{\\delta t}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bc0c49d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHS: 0.11919670816963901\n",
      "RHS: 0.11919670816968986\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, checkpoint\n",
    "jax.config.update(\"jax_enable_x64\", True)  # force 64-bit accuracy\n",
    "\n",
    "\n",
    "def simulate_gbm(S0, mu, sigma, T, dt, key):\n",
    "    num_steps = int(T / dt)\n",
    "    increments = random.normal(key, (num_steps,)) * jnp.sqrt(dt)\n",
    "#     time_steps = jnp.linspace(dt, T, num_steps)\n",
    "    S_path = [S0]\n",
    "    for i in range(num_steps):\n",
    "        S_path.append(S_path[-1]*(1+mu*dt+sigma*increments[i]))\n",
    "#         S_path.append(S_path[-1]*jnp.exp((mu - 0.5 * sigma**2)*dt+sigma*increments[i]))    \n",
    "    return S_path[-1]\n",
    "\n",
    "\n",
    "def forward_mode_gbm(S0, mu, sigma, T, dt, key, a_dot, b_dot, c_dot):\n",
    "    gbm_func = lambda x: simulate_gbm(x[0], x[1], x[2], T, dt, key)\n",
    "    inputs = jnp.array([S0, mu, sigma])\n",
    "    tangents = jnp.array([a_dot, b_dot, c_dot])  # Change to calculate sensitivity w.r.t. each input\n",
    "    _, g_dot = jax.jvp(gbm_func, (inputs,), (tangents,))\n",
    "    return g_dot\n",
    "\n",
    "def reverse_mode_gbm(S0, mu, sigma, T, dt, key, g_bar):\n",
    "    def gbm_func(S0, mu, sigma):\n",
    "        return simulate_gbm(S0, mu, sigma, T, dt, key)\n",
    "    _, vjp_fun = jax.vjp(gbm_func, S0, mu, sigma)\n",
    "    g_bar = 1.0  # Sensitivity of the loss w.r.t. output\n",
    "    return vjp_fun(g_bar)\n",
    "\n",
    "S0, mu, sigma = 100.0, 0.05, 0.2\n",
    "T, dt = 1.0, 0.01\n",
    "key = random.PRNGKey(0)\n",
    "g_bar = 1.0\n",
    "a_dot, b_dot, c_dot = 1.0,1.0,1.0\n",
    "\n",
    "# Calculate forward and reverse mode derivatives\n",
    "g_dot = forward_mode_gbm(S0, mu, sigma, T, dt, key, a_dot, b_dot, c_dot)\n",
    "a_bar, b_bar, c_bar = reverse_mode_gbm(S0, mu, sigma, T, dt, key, g_bar)\n",
    "\n",
    "# Assume the forward and reverse are the same for demonstration\n",
    "lhs = sum(jnp.array([a_dot, b_dot, c_dot]) * jnp.array([a_bar, b_bar, c_bar]))\n",
    "rhs = g_dot * g_bar  # g_bar assumed to be same as g_dot for simplicity\n",
    "\n",
    "print(\"LHS:\", lhs)\n",
    "print(\"RHS:\", rhs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa248ff7",
   "metadata": {},
   "source": [
    "## checkpointing using jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95629f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHS: 2.567828732334462\n",
      "RHS: 2.567828732334464\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, checkpoint\n",
    "jax.config.update(\"jax_enable_x64\", True)  # force 64-bit accuracy\n",
    "\n",
    "\n",
    "def simulate_gbm(S0, mu, sigma, T, dt, key):\n",
    "    num_steps = int(T / dt)\n",
    "    increments = random.normal(key, (num_steps,)) * jnp.sqrt(dt)\n",
    "    time_steps = jnp.linspace(dt, T, num_steps)\n",
    "    log_path = (mu - 0.5 * sigma**2) * time_steps + sigma * increments.cumsum(axis=0)\n",
    "    S_path = S0 * jnp.exp(log_path)\n",
    "    return S_path[-1]\n",
    "\n",
    "ckpt_simulate_gbm = checkpoint(simulate_gbm, static_argnums=(3, 4))\n",
    "\n",
    "def forward_mode_gbm(S0, mu, sigma, T, dt, key, a_dot, b_dot, c_dot):\n",
    "    gbm_func = lambda x: ckpt_simulate_gbm(x[0], x[1], x[2], T, dt, key)\n",
    "    inputs = jnp.array([S0, mu, sigma])\n",
    "    tangents = jnp.array([a_dot, b_dot, c_dot])  # Change to calculate sensitivity w.r.t. each input\n",
    "    _, g_dot = jax.jvp(gbm_func, (inputs,), (tangents,))\n",
    "    return g_dot\n",
    "\n",
    "def reverse_mode_gbm(S0, mu, sigma, T, dt, key, g_bar):\n",
    "    def gbm_func(S0, mu, sigma):\n",
    "        return ckpt_simulate_gbm(S0, mu, sigma, T, dt, key)\n",
    "    _, vjp_fun = jax.vjp(gbm_func, S0, mu, sigma)\n",
    "    g_bar = 1.0  # Sensitivity of the loss w.r.t. output\n",
    "    return vjp_fun(g_bar)\n",
    "\n",
    "S0, mu, sigma = 100.0, 0.05, 0.2\n",
    "T, dt = 1.0, 0.01\n",
    "key = random.PRNGKey(0)\n",
    "g_bar = 1.0\n",
    "a_dot, b_dot, c_dot = 1.0,1.0,1.0\n",
    "\n",
    "# Calculate forward and reverse mode derivatives\n",
    "g_dot = forward_mode_gbm(S0, mu, sigma, T, dt, key, a_dot, b_dot, c_dot)\n",
    "a_bar, b_bar, c_bar = reverse_mode_gbm(S0, mu, sigma, T, dt, key, g_bar)\n",
    "\n",
    "# Assume the forward and reverse are the same for demonstration\n",
    "lhs = sum(jnp.array([a_dot, b_dot, c_dot]) * jnp.array([a_bar, b_bar, c_bar]))\n",
    "rhs = g_dot * g_bar  # g_bar assumed to be same as g_dot for simplicity\n",
    "\n",
    "print(\"LHS:\", lhs)\n",
    "print(\"RHS:\", rhs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e58f52a",
   "metadata": {},
   "source": [
    "### using for loop here "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce38d344",
   "metadata": {},
   "source": [
    "testing with different simulation formula from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2d59f314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHS: 0.11919670816963901\n",
      "RHS: 0.11919670816966921\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, checkpoint\n",
    "jax.config.update(\"jax_enable_x64\", True)  # force 64-bit accuracy\n",
    "\n",
    "\n",
    "def simulate_gbm(S0, mu, sigma, T, dt, key):\n",
    "    num_steps = int(T / dt)\n",
    "    increments = random.normal(key, (num_steps,)) * jnp.sqrt(dt)\n",
    "#     time_steps = jnp.linspace(dt, T, num_steps)\n",
    "    S_path = [S0]\n",
    "    for i in range(num_steps):\n",
    "        S_path.append(S_path[-1]*(1+mu*dt+sigma*increments[i]))\n",
    "#         S_path.append(S_path[-1]*jnp.exp((mu - 0.5 * sigma**2)*dt+sigma*increments[i]))    \n",
    "    return S_path[-1]\n",
    "\n",
    "ckpt_simulate_gbm = checkpoint(simulate_gbm, static_argnums=(3, 4))\n",
    "\n",
    "def forward_mode_gbm(S0, mu, sigma, T, dt, key, a_dot, b_dot, c_dot):\n",
    "    gbm_func = lambda x: ckpt_simulate_gbm(x[0], x[1], x[2], T, dt, key)\n",
    "    inputs = jnp.array([S0, mu, sigma])\n",
    "    tangents = jnp.array([a_dot, b_dot, c_dot])  # Change to calculate sensitivity w.r.t. each input\n",
    "    _, g_dot = jax.jvp(gbm_func, (inputs,), (tangents,))\n",
    "    return g_dot\n",
    "\n",
    "def reverse_mode_gbm(S0, mu, sigma, T, dt, key, g_bar):\n",
    "    def gbm_func(S0, mu, sigma):\n",
    "        return ckpt_simulate_gbm(S0, mu, sigma, T, dt, key)\n",
    "    _, vjp_fun = jax.vjp(gbm_func, S0, mu, sigma)\n",
    "    g_bar = 1.0  # Sensitivity of the loss w.r.t. output\n",
    "    return vjp_fun(g_bar)\n",
    "\n",
    "S0, mu, sigma = 100.0, 0.05, 0.2\n",
    "T, dt = 1.0, 0.01\n",
    "key = random.PRNGKey(0)\n",
    "g_bar = 1.0\n",
    "a_dot, b_dot, c_dot = 1.0,1.0,1.0\n",
    "\n",
    "# Calculate forward and reverse mode derivatives\n",
    "g_dot = forward_mode_gbm(S0, mu, sigma, T, dt, key, a_dot, b_dot, c_dot)\n",
    "a_bar, b_bar, c_bar = reverse_mode_gbm(S0, mu, sigma, T, dt, key, g_bar)\n",
    "\n",
    "# Assume the forward and reverse are the same for demonstration\n",
    "lhs = sum(jnp.array([a_dot, b_dot, c_dot]) * jnp.array([a_bar, b_bar, c_bar]))\n",
    "rhs = g_dot * g_bar  # g_bar assumed to be same as g_dot for simplicity\n",
    "\n",
    "print(\"LHS:\", lhs)\n",
    "print(\"RHS:\", rhs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768f8929",
   "metadata": {},
   "source": [
    "## not using jax.checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9be920",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e8e2c4",
   "metadata": {},
   "source": [
    "below is more like the one-step checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "26896384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad, jit, vjp, jvp\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True) \n",
    "\n",
    "def compute_increments(dt, num_steps, key):\n",
    "    return random.normal(key, (num_steps,)) * jnp.sqrt(dt)\n",
    "\n",
    "def compute_final_price(S0, mu, sigma, increments, time_steps):\n",
    "    num_steps = int((T)/ dt)\n",
    "    S_path = [S0]\n",
    "    for i in range(num_steps):\n",
    "        S_path.append(S_path[-1]*(1+mu*dt+sigma*increments[i]))\n",
    "    return S_path[-1]\n",
    "\n",
    "def simulate_gbm(S0, mu, sigma, T, dt, key):\n",
    "    num_steps = int(T / dt)\n",
    "    time_steps = jnp.linspace(dt, T, num_steps)\n",
    "    increments = compute_increments(dt, num_steps, key)\n",
    "    final_price = compute_final_price(S0, mu, sigma, increments, time_steps)\n",
    "    return final_price\n",
    "\n",
    "# for manually checkpointing\n",
    "def forward_and_save_intermediates(S0, mu, sigma, T, dt, key):\n",
    "    num_steps = int(T / dt)\n",
    "    time_steps = jnp.linspace(dt, T, num_steps)\n",
    "    increments = compute_increments(dt, num_steps, key)\n",
    "    # Save increments and time_steps for recomputation\n",
    "    return S0, mu, sigma, increments, time_steps\n",
    "\n",
    "def manual_checkpoint_gbm_grad(S0, mu, sigma, T, dt, key):\n",
    "    S0, mu, sigma, increments, time_steps = forward_and_save_intermediates(S0, mu, sigma, T, dt, key)\n",
    "    \n",
    "    def backward_from_saved(S0, mu, sigma):\n",
    "        return compute_final_price(S0, mu, sigma, increments, time_steps)\n",
    "    \n",
    "    g, vjp_fun = vjp(lambda S0, mu, sigma: backward_from_saved(S0, mu, sigma), S0, mu, sigma)\n",
    "    g_bar = jnp.array(1.0)\n",
    "    gradients = vjp_fun(g_bar)\n",
    "    return gradients\n",
    "\n",
    "S0 = 100.0  # Initial price\n",
    "mu = 0.05   # Drift\n",
    "sigma = 0.2 # Volatility\n",
    "T = 1.0     # Time horizon\n",
    "dt = 0.01   # Time step\n",
    "key = random.PRNGKey(0)\n",
    "\n",
    "gradients = manual_checkpoint_gbm_grad(S0, mu, sigma, T, dt, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6be76f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(0.87897801, dtype=float64, weak_type=True),\n",
       " Array(88.03136753, dtype=float64, weak_type=True),\n",
       " Array(-88.79114883, dtype=float64, weak_type=True))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d1456",
   "metadata": {},
   "source": [
    "this is the LHS: S0_bar$*$S0_dot + sigma_bar$*$sigma_dot + mu_bar$*$mu_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20a5bc1",
   "metadata": {},
   "source": [
    "the result is the same as the 2.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "662d8f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.11919671, dtype=float64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(jnp.array([a_dot, b_dot, c_dot]) * jnp.array(gradients))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1714857b",
   "metadata": {},
   "source": [
    "### jax in reverse mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "677b024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad, jit, vjp, jvp\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True) \n",
    "\n",
    "def compute_increments(dt, num_steps, key):\n",
    "    return random.normal(key, (num_steps,)) * jnp.sqrt(dt)\n",
    "\n",
    "def compute_step_price(S0, mu, sigma, increments, t0, T, dt):\n",
    "    num_steps = round((T-t0)/ dt)\n",
    "    if num_steps == 0:\n",
    "        print(T,t0)\n",
    "    S_path = [S0]\n",
    "    for i in range(num_steps):\n",
    "        S_path.append(S_path[-1]*(1+mu*dt+sigma*increments[i]))\n",
    "#         S_path.append(S_path[-1]*jnp.exp((mu - 0.5 * sigma**2)*dt+sigma*increments[i]))    \n",
    "    return S_path\n",
    "\n",
    "# for manually checkpointing\n",
    "def forward_and_save_intermediates(S0, mu, sigma, T, dt, key):\n",
    "    num_steps = round(T / dt)\n",
    "#     time_steps = jnp.linspace(dt, T, num_steps)\n",
    "    increments = compute_increments(dt, num_steps, key)\n",
    "    # Save increments and time_steps for recomputation\n",
    "    state_price = compute_step_price(S0, mu, sigma, increments, 0, T, dt)\n",
    "    return S0, mu, sigma, increments, state_price\n",
    "\n",
    "def manual_checkpoint_gbm_grad(S0, mu, sigma, T, dt, key):\n",
    "    S0, mu, sigma, increments, state_price = forward_and_save_intermediates(S0, mu, sigma, T, dt, key)\n",
    "    num_steps = round(T / dt)\n",
    "    g_bar = jnp.array(1.0)\n",
    "    mu_grad = 0.0\n",
    "    sigma_grad = 0.0\n",
    "    S0_grad = 0.0\n",
    "    for i in reversed(range(num_steps)):\n",
    "        S0 = state_price[i]\n",
    "        def step_fn(S0, mu, sigma):\n",
    "            return compute_step_price(S0, mu, sigma, increments[i:i+1], dt*i, dt*(i+1), dt)[-1]   \n",
    "        _, vjp_fun = vjp(step_fn, S0, mu, sigma)\n",
    "        g_bar, mu_bar, sigma_bar = vjp_fun(g_bar)\n",
    "\n",
    "        mu_grad += mu_bar\n",
    "        sigma_grad += sigma_bar\n",
    "        if i == 0:\n",
    "            S0_grad = g_bar\n",
    "\n",
    "    return S0_grad, mu_grad, sigma_grad\n",
    "\n",
    "S0 = 100.0  # Initial price\n",
    "mu = 0.05   # Drift\n",
    "sigma = 0.2 # Volatility\n",
    "T = 1.0     # Time horizon\n",
    "dt = 0.01   # Time step\n",
    "key = random.PRNGKey(0)\n",
    "\n",
    "gradients = manual_checkpoint_gbm_grad(S0, mu, sigma, T, dt, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c09c5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(0.87897801, dtype=float64, weak_type=True),\n",
       " Array(88.03136753, dtype=float64, weak_type=True),\n",
       " Array(-88.79114883, dtype=float64, weak_type=True))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4362597a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.11919671, dtype=float64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(jnp.array([a_dot, b_dot, c_dot]) * jnp.array(gradients))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbb8ee1",
   "metadata": {},
   "source": [
    "### totally manual calculation in reverse mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "716b2107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad, jit, vjp, jvp\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True) \n",
    "\n",
    "def compute_increments(dt, num_steps, key):\n",
    "    return random.normal(key, (num_steps,)) * jnp.sqrt(dt)\n",
    "\n",
    "def compute_step_price(S0, mu, sigma, increments, t0, T, dt):\n",
    "    num_steps = round((T-t0)/ dt)\n",
    "    if num_steps == 0:\n",
    "        print(T,t0)\n",
    "    S_path = [S0]\n",
    "    for i in range(num_steps):\n",
    "        S_path.append(S_path[-1]*(1+mu*dt+sigma*increments[i]))\n",
    "#         S_path.append(S_path[-1]*jnp.exp((mu - 0.5 * sigma**2)*dt+sigma*increments[i]))    \n",
    "    return S_path\n",
    "\n",
    "# for manually checkpointing\n",
    "def forward_and_save_intermediates(S0, mu, sigma, T, dt, key):\n",
    "    num_steps = round(T / dt)\n",
    "#     time_steps = jnp.linspace(dt, T, num_steps)\n",
    "    increments = compute_increments(dt, num_steps, key)\n",
    "    # Save increments and time_steps for recomputation\n",
    "    state_price = compute_step_price(S0, mu, sigma, increments, 0, T, dt)\n",
    "    return S0, mu, sigma, increments, state_price\n",
    "\n",
    "def manual_checkpoint_gbm_grad(S0, mu, sigma, T, dt, key):\n",
    "    S0, mu, sigma, increments, state_price = forward_and_save_intermediates(S0, mu, sigma, T, dt, key)\n",
    "    num_steps = round(T / dt)\n",
    "    g_bar = jnp.array(1.0)\n",
    "    mu_grad = 0.0\n",
    "    sigma_grad = 0.0\n",
    "    S0_grad = 0.0\n",
    "    for i in reversed(range(num_steps)):\n",
    "        S0 = state_price[i]\n",
    "        mu_bar = S0*dt*g_bar\n",
    "        sigma_bar = S0*increments[i]*g_bar\n",
    "        g_bar = (1+mu*dt+sigma*increments[i])*g_bar\n",
    "\n",
    "        mu_grad += mu_bar\n",
    "        sigma_grad += sigma_bar\n",
    "        if i == 0:\n",
    "            S0_grad = g_bar\n",
    "\n",
    "    return S0_grad, mu_grad, sigma_grad\n",
    "\n",
    "S0 = 100.0  # Initial price\n",
    "mu = 0.05   # Drift\n",
    "sigma = 0.2 # Volatility\n",
    "T = 1.0     # Time horizon\n",
    "dt = 0.01   # Time step\n",
    "key = random.PRNGKey(0)\n",
    "\n",
    "gradients = manual_checkpoint_gbm_grad(S0, mu, sigma, T, dt, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6a47c040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(0.87897801, dtype=float64),\n",
       " Array(88.03136753, dtype=float64),\n",
       " Array(-88.79114883, dtype=float64))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "10ac7e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.11919671, dtype=float64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(jnp.array([a_dot, b_dot, c_dot]) * jnp.array(gradients))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0909e5b",
   "metadata": {},
   "source": [
    "# control flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "750346cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_flow(a=2,b=3,c=4, a_dot=1, b_dot=1, c_dot=1, g_bar=1):\n",
    "    \n",
    "    def output(a, b, c):\n",
    "        d = b+c\n",
    "        e = a*c\n",
    "        l = e > d\n",
    "        if l:\n",
    "            f = d - e\n",
    "        else:\n",
    "            f = d + e\n",
    "        g = e/f\n",
    "        return d,e,f,g,l\n",
    "    \n",
    "    def forward(a,b,c,d,e,f,g,l,a_dot, b_dot, c_dot):\n",
    "        d_dot = b_dot + c_dot\n",
    "        e_dot = a_dot*c + a*c_dot\n",
    "        if l:\n",
    "            f_dot = d_dot - e_dot\n",
    "        else:\n",
    "            f_dot = d_dot + e_dot\n",
    "        g_dot = 1.0/(f*f)*(e_dot*f - e*f_dot)\n",
    "        return g_dot\n",
    "    \n",
    "    def backward(a,b,c,d,e,f,g,l,g_bar):\n",
    "        f_bar = -e/(f*f)*g_bar\n",
    "        e_bar = 1.0/f*g_bar\n",
    "        d_bar = f_bar\n",
    "        if l:\n",
    "            e_bar -= f_bar\n",
    "        else:\n",
    "            e_bar += f_bar\n",
    "        a_bar = e_bar*c\n",
    "        c_bar = e_bar*a\n",
    "        b_bar = d_bar\n",
    "        c_bar += d_bar\n",
    "        return a_bar, b_bar, c_bar\n",
    "    \n",
    "    def validation(a_dot, b_dot, c_dot, g_dot, a_bar, b_bar, c_bar, g_bar):\n",
    "        LHS = a_dot*a_bar + b_dot*b_bar + c_dot*c_bar\n",
    "        RHS = g_dot*g_bar\n",
    "        print(LHS,RHS,f'error:{abs(LHS-RHS)}')\n",
    "    \n",
    "    d,e,f,g,l = output(a,b,c)\n",
    "    g_dot = forward(a,b,c,d,e,f,g,l,a_dot, b_dot, c_dot)\n",
    "    a_bar, b_bar, c_bar = backward(a,b,c,d,e,f,g,l,g_bar)\n",
    "    validation(a_dot, b_dot, c_dot, g_dot, a_bar, b_bar, c_bar, g_bar)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2f058e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.0 26.0 error:0.0\n"
     ]
    }
   ],
   "source": [
    "control_flow(a=2,b=3,c=4, a_dot=1, b_dot=1, c_dot=1, g_bar=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67d3c8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward mode gradient g_dot: 26.0\n",
      "Reverse mode gradients a_bar, b_bar, c_bar: 28.0 -8.0 6.0\n",
      "Left-hand side (Input Sensitivity Product): 26.0\n",
      "Right-hand side (Output Sensitivity Product): 26.0\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def output(a, b, c):\n",
    "    d = b+c\n",
    "    e = a*c\n",
    "    l = e > d\n",
    "    if l:\n",
    "        f = d - e\n",
    "    else:\n",
    "        f = d + e\n",
    "    g = e/f\n",
    "    return g\n",
    "\n",
    "# Set the initial values for a, b, c\n",
    "a, b, c = 2.0, 3.0, 4.0  # Example values\n",
    "\n",
    "# Set the sensitivities (tangents) for a, b, c\n",
    "a_dot, b_dot, c_dot = 1.0, 1.0, 1.0  # Example sensitivities\n",
    "\n",
    "# Function to compute forward mode derivative of g with respect to a, b, c\n",
    "def compute_forward_gradient(a, b, c, a_dot, b_dot, c_dot):\n",
    "    # Wrap the function to use with jax.jvp\n",
    "    def func(inputs):\n",
    "        a, b, c = inputs\n",
    "        return output(a, b, c)\n",
    "\n",
    "    # Inputs and their perturbations\n",
    "    inputs = jnp.array([a, b, c])\n",
    "    tangents = jnp.array([a_dot, b_dot, c_dot])\n",
    "\n",
    "    # Compute the Jacobian-vector product\n",
    "    _, g_dot = jax.jvp(func, (inputs,), (tangents,))\n",
    "    return g_dot\n",
    "\n",
    "# Compute g_dot\n",
    "g_dot = compute_forward_gradient(a, b, c, a_dot, b_dot, c_dot)\n",
    "print(\"Forward mode gradient g_dot:\", g_dot)\n",
    "\n",
    "# Function to compute reverse mode gradient of a, b, c given g_bar\n",
    "def compute_reverse_gradient(a, b, c, g_bar):\n",
    "    # Wrap the function to use with jax.vjp\n",
    "    def func(a, b, c):\n",
    "        return output(a, b, c)\n",
    "    \n",
    "    # Get the function output and vjp function\n",
    "    g, vjp_fun = jax.vjp(func, a, b, c)\n",
    "\n",
    "    # Compute the vector-Jacobian product\n",
    "    a_bar, b_bar, c_bar = vjp_fun(g_bar)\n",
    "    return a_bar, b_bar, c_bar\n",
    "\n",
    "# Assume g_bar is given (the sensitivity of the loss with respect to g)\n",
    "g_bar = 1.0  # Example sensitivity of the loss with respect to g\n",
    "\n",
    "# Compute a_bar, b_bar, c_bar\n",
    "a_bar, b_bar, c_bar = compute_reverse_gradient(a, b, c, g_bar)\n",
    "print(\"Reverse mode gradients a_bar, b_bar, c_bar:\", a_bar, b_bar, c_bar)\n",
    "\n",
    "\n",
    "# Calculate the dot products\n",
    "lhs = a_dot * a_bar + b_dot * b_bar + c_dot * c_bar\n",
    "rhs = g_dot * g_bar\n",
    "\n",
    "print(f\"Left-hand side (Input Sensitivity Product): {lhs}\")\n",
    "print(f\"Right-hand side (Output Sensitivity Product): {rhs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815617de",
   "metadata": {},
   "source": [
    "# performance comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8433ddc2",
   "metadata": {},
   "source": [
    "Set T = 100 and dt = 0.01, test the execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ccdca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0dfb4e",
   "metadata": {},
   "source": [
    "## manual checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33c2485e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHS: 4.318122574486458e+16\n",
      "Execution time: 12.584457874298096 seconds\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad, jit, vjp, jvp\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True) \n",
    "\n",
    "def compute_increments(dt, num_steps, key):\n",
    "    return random.normal(key, (num_steps,)) * jnp.sqrt(dt)\n",
    "\n",
    "def compute_step_price(S0, mu, sigma, increments, t0, T, dt):\n",
    "    num_steps = round((T-t0)/ dt)\n",
    "    if num_steps == 0:\n",
    "        print(T,t0)\n",
    "    S_path = [S0]\n",
    "    for i in range(num_steps):\n",
    "        S_path.append(S_path[-1]*(1+mu*dt+sigma*increments[i]))\n",
    "#         S_path.append(S_path[-1]*jnp.exp((mu - 0.5 * sigma**2)*dt+sigma*increments[i]))    \n",
    "    return S_path\n",
    "\n",
    "# for manually checkpointing\n",
    "def forward_and_save_intermediates(S0, mu, sigma, T, dt, key):\n",
    "    num_steps = round(T / dt)\n",
    "#     time_steps = jnp.linspace(dt, T, num_steps)\n",
    "    increments = compute_increments(dt, num_steps, key)\n",
    "    # Save increments and time_steps for recomputation\n",
    "    state_price = compute_step_price(S0, mu, sigma, increments, 0, T, dt)\n",
    "    return S0, mu, sigma, increments, state_price\n",
    "\n",
    "def manual_checkpoint_gbm_grad(S0, mu, sigma, T, dt, key):\n",
    "    S0, mu, sigma, increments, state_price = forward_and_save_intermediates(S0, mu, sigma, T, dt, key)\n",
    "    num_steps = round(T / dt)\n",
    "    g_bar = jnp.array(1.0)\n",
    "    mu_grad = 0.0\n",
    "    sigma_grad = 0.0\n",
    "    S0_grad = 0.0\n",
    "    for i in reversed(range(num_steps)):\n",
    "        S0 = state_price[i]\n",
    "        mu_bar = S0*dt*g_bar\n",
    "        sigma_bar = S0*increments[i]*g_bar\n",
    "        g_bar = (1+mu*dt+sigma*increments[i])*g_bar\n",
    "\n",
    "        mu_grad += mu_bar\n",
    "        sigma_grad += sigma_bar\n",
    "        if i == 0:\n",
    "            S0_grad = g_bar\n",
    "\n",
    "    return S0_grad, mu_grad, sigma_grad\n",
    "\n",
    "S0 = 100.0  # Initial price\n",
    "mu = 0.05   # Drift\n",
    "sigma = 0.2 # Volatility\n",
    "T = 1000.0     # Time horizon\n",
    "dt = 0.01   # Time step\n",
    "key = random.PRNGKey(0)\n",
    "\n",
    "start_time = time.time()\n",
    "gradients = manual_checkpoint_gbm_grad(S0, mu, sigma, T, dt, key)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "lhs = sum(jnp.array([a_dot, b_dot, c_dot]) * jnp.array(gradients))\n",
    "print('LHS:',lhs)\n",
    "print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00206d54",
   "metadata": {},
   "source": [
    "## jax.checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9ba0928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHS: 4.318122574486458e+16\n",
      "RHS: 4.318122574486346e+16\n",
      "Execution time: 616.5304710865021 seconds\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, checkpoint\n",
    "jax.config.update(\"jax_enable_x64\", True)  # force 64-bit accuracy\n",
    "\n",
    "\n",
    "def simulate_gbm(S0, mu, sigma, T, dt, key):\n",
    "    num_steps = int(T / dt)\n",
    "    increments = random.normal(key, (num_steps,)) * jnp.sqrt(dt)\n",
    "#     time_steps = jnp.linspace(dt, T, num_steps)\n",
    "    S_path = [S0]\n",
    "    for i in range(num_steps):\n",
    "        S_path.append(S_path[-1]*(1+mu*dt+sigma*increments[i]))\n",
    "#         S_path.append(S_path[-1]*jnp.exp((mu - 0.5 * sigma**2)*dt+sigma*increments[i]))    \n",
    "    return S_path[-1]\n",
    "\n",
    "ckpt_simulate_gbm = checkpoint(simulate_gbm, static_argnums=(3, 4))\n",
    "\n",
    "def forward_mode_gbm(S0, mu, sigma, T, dt, key, a_dot, b_dot, c_dot):\n",
    "    gbm_func = lambda x: ckpt_simulate_gbm(x[0], x[1], x[2], T, dt, key)\n",
    "    inputs = jnp.array([S0, mu, sigma])\n",
    "    tangents = jnp.array([a_dot, b_dot, c_dot])  # Change to calculate sensitivity w.r.t. each input\n",
    "    _, g_dot = jax.jvp(gbm_func, (inputs,), (tangents,))\n",
    "    return g_dot\n",
    "\n",
    "def reverse_mode_gbm(S0, mu, sigma, T, dt, key, g_bar):\n",
    "    def gbm_func(S0, mu, sigma):\n",
    "        return ckpt_simulate_gbm(S0, mu, sigma, T, dt, key)\n",
    "    _, vjp_fun = jax.vjp(gbm_func, S0, mu, sigma)\n",
    "    g_bar = 1.0  # Sensitivity of the loss w.r.t. output\n",
    "    return vjp_fun(g_bar)\n",
    "\n",
    "S0, mu, sigma = 100.0, 0.05, 0.2\n",
    "T, dt = 1000.0, 0.01\n",
    "key = random.PRNGKey(0)\n",
    "g_bar = 1.0\n",
    "a_dot, b_dot, c_dot = 1.0,1.0,1.0\n",
    "\n",
    "# Calculate forward and reverse mode derivatives\n",
    "start_time = time.time()\n",
    "g_dot = forward_mode_gbm(S0, mu, sigma, T, dt, key, a_dot, b_dot, c_dot)\n",
    "a_bar, b_bar, c_bar = reverse_mode_gbm(S0, mu, sigma, T, dt, key, g_bar)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# Assume the forward and reverse are the same for demonstration\n",
    "lhs = sum(jnp.array([a_dot, b_dot, c_dot]) * jnp.array([a_bar, b_bar, c_bar]))\n",
    "rhs = g_dot * g_bar  # g_bar assumed to be same as g_dot for simplicity\n",
    "\n",
    "print(\"LHS:\", lhs)\n",
    "print(\"RHS:\", rhs)\n",
    "\n",
    "print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85a6a64",
   "metadata": {},
   "source": [
    "## no checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c608380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHS: 4.318122574486458e+16\n",
      "RHS: 4.318122574486579e+16\n",
      "Execution time: 239.1335198879242 seconds\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random, checkpoint\n",
    "jax.config.update(\"jax_enable_x64\", True)  # force 64-bit accuracy\n",
    "\n",
    "\n",
    "def simulate_gbm(S0, mu, sigma, T, dt, key):\n",
    "    num_steps = int(T / dt)\n",
    "    increments = random.normal(key, (num_steps,)) * jnp.sqrt(dt)\n",
    "#     time_steps = jnp.linspace(dt, T, num_steps)\n",
    "    S_path = [S0]\n",
    "    for i in range(num_steps):\n",
    "        S_path.append(S_path[-1]*(1+mu*dt+sigma*increments[i]))\n",
    "#         S_path.append(S_path[-1]*jnp.exp((mu - 0.5 * sigma**2)*dt+sigma*increments[i]))    \n",
    "    return S_path[-1]\n",
    "\n",
    "\n",
    "def forward_mode_gbm(S0, mu, sigma, T, dt, key, a_dot, b_dot, c_dot):\n",
    "    gbm_func = lambda x: simulate_gbm(x[0], x[1], x[2], T, dt, key)\n",
    "    inputs = jnp.array([S0, mu, sigma])\n",
    "    tangents = jnp.array([a_dot, b_dot, c_dot])  # Change to calculate sensitivity w.r.t. each input\n",
    "    _, g_dot = jax.jvp(gbm_func, (inputs,), (tangents,))\n",
    "    return g_dot\n",
    "\n",
    "def reverse_mode_gbm(S0, mu, sigma, T, dt, key, g_bar):\n",
    "    def gbm_func(S0, mu, sigma):\n",
    "        return simulate_gbm(S0, mu, sigma, T, dt, key)\n",
    "    _, vjp_fun = jax.vjp(gbm_func, S0, mu, sigma)\n",
    "    g_bar = 1.0  # Sensitivity of the loss w.r.t. output\n",
    "    return vjp_fun(g_bar)\n",
    "\n",
    "S0, mu, sigma = 100.0, 0.05, 0.2\n",
    "T, dt = 1000.0, 0.01\n",
    "key = random.PRNGKey(0)\n",
    "g_bar = 1.0\n",
    "a_dot, b_dot, c_dot = 1.0,1.0,1.0\n",
    "\n",
    "# Calculate forward and reverse mode derivatives\n",
    "start_time = time.time()\n",
    "g_dot = forward_mode_gbm(S0, mu, sigma, T, dt, key, a_dot, b_dot, c_dot)\n",
    "a_bar, b_bar, c_bar = reverse_mode_gbm(S0, mu, sigma, T, dt, key, g_bar)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# Assume the forward and reverse are the same for demonstration\n",
    "lhs = sum(jnp.array([a_dot, b_dot, c_dot]) * jnp.array([a_bar, b_bar, c_bar]))\n",
    "rhs = g_dot * g_bar  # g_bar assumed to be same as g_dot for simplicity\n",
    "\n",
    "print(\"LHS:\", lhs)\n",
    "print(\"RHS:\", rhs)\n",
    "print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7281c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
