{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "484489de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e34af9",
   "metadata": {},
   "source": [
    "# doing by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a7b245",
   "metadata": {},
   "source": [
    "## case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88e83c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_1(a=2,b=3,c=4, a_dot=1, b_dot=1, c_dot=1, g_bar=1):\n",
    "    \n",
    "    def output(a, b, c):\n",
    "        d = b+c\n",
    "        e= a*c\n",
    "        f= d+e\n",
    "        g = e/f\n",
    "        return d,e,f,g\n",
    "    \n",
    "    def forward(a,b,c,d,e,f,g,a_dot, b_dot, c_dot):\n",
    "        d_dot = b_dot + c_dot\n",
    "        e_dot = a_dot*c + a*c_dot\n",
    "        f_dot = d_dot + e_dot\n",
    "        g_dot = 1.0/(f*f)*(e_dot*f - e*f_dot)\n",
    "        return g_dot\n",
    "    \n",
    "    def backward(a,b,c,d,e,f,g,g_bar):\n",
    "        f_bar = -e/(f*f)*g_bar\n",
    "        e_bar = 1.0/f*g_bar\n",
    "        d_bar = f_bar\n",
    "        e_bar += f_bar\n",
    "        a_bar = e_bar*c\n",
    "        c_bar = e_bar*a\n",
    "        b_bar = d_bar\n",
    "        c_bar += d_bar\n",
    "        return a_bar, b_bar, c_bar\n",
    "    \n",
    "    def validation(a_dot, b_dot, c_dot, g_dot, a_bar, b_bar, c_bar, g_bar):\n",
    "        LHS = a_dot*a_bar + b_dot*b_bar + c_dot*c_bar\n",
    "        RHS = g_dot*g_bar\n",
    "        print(LHS,RHS,f'error:{abs(LHS-RHS)}')\n",
    "    \n",
    "    d,e,f,g = output(a,b,c)\n",
    "    g_dot = forward(a,b,c,d,e,f,g,a_dot, b_dot, c_dot)\n",
    "    a_bar, b_bar, c_bar = backward(a,b,c,d,e,f,g,g_bar)\n",
    "    validation(a_dot, b_dot, c_dot, g_dot, a_bar, b_bar, c_bar, g_bar)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de4b18a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11555555555555555 0.11555555555555555 error:0.0\n"
     ]
    }
   ],
   "source": [
    "test_1(a=2,b=3,c=4, a_dot=1, b_dot=1, c_dot=1, g_bar=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf61bf58",
   "metadata": {},
   "source": [
    "## case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "907d4069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_2(a=2,b=3,c=4, a_dot=1, b_dot=1, c_dot=1, g_bar=1):\n",
    "    \n",
    "    def output(a, b, c):\n",
    "        d = b+c\n",
    "        e= a*c\n",
    "        e_ = e\n",
    "        f= d+e\n",
    "        g = f*e\n",
    "        e = np.exp(g)\n",
    "        g += e\n",
    "        return d,e,f,g, e_\n",
    "    \n",
    "    def forward(a,b,c,d,e,f,g,e_,a_dot, b_dot, c_dot):\n",
    "        d_dot = b_dot + c_dot\n",
    "        e_dot = a_dot*c + a*c_dot\n",
    "        f_dot = d_dot + e_dot\n",
    "        g_dot = f_dot*e_ + f*e_dot\n",
    "        e_dot = e*g_dot\n",
    "        g_dot += e_dot\n",
    "        return g_dot\n",
    "    \n",
    "    def backward(a,b,c,d,e,f,g,e_,g_bar):\n",
    "        e_bar = g_bar\n",
    "        g_bar = g_bar\n",
    "        g_bar += e_bar*e\n",
    "        f_bar = g_bar*e_\n",
    "        e_bar = g_bar*f\n",
    "        d_bar = f_bar\n",
    "        e_bar += f_bar\n",
    "        a_bar = e_bar*c\n",
    "        c_bar = e_bar*a\n",
    "        b_bar = d_bar\n",
    "        c_bar += d_bar\n",
    "        return a_bar, b_bar, c_bar\n",
    "    \n",
    "    def validation(a_dot, b_dot, c_dot, g_dot, a_bar, b_bar, c_bar, g_bar):\n",
    "        LHS = a_dot*a_bar + b_dot*b_bar + c_dot*c_bar\n",
    "        RHS = g_dot*g_bar\n",
    "        print(LHS,RHS,f'error:{abs(LHS-RHS)}')\n",
    "    \n",
    "    d,e,f,g,e_ = output(a,b,c)\n",
    "    g_dot = forward(a,b,c,d,e,f,g,e_,a_dot, b_dot, c_dot)\n",
    "    a_bar, b_bar, c_bar = backward(a,b,c,d,e,f,g,e_,g_bar)\n",
    "    validation(a_dot, b_dot, c_dot, g_dot, a_bar, b_bar, c_bar, g_bar)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c871850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.025315658178581e+54 6.025315658178581e+54 error:0.0\n"
     ]
    }
   ],
   "source": [
    "test_2(a=2,b=3,c=4, a_dot=1, b_dot=1, c_dot=1, g_bar=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aff149",
   "metadata": {},
   "source": [
    "## simple matrix case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "876e11f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_3(A,B,A_dot,B_dot,C_bar):\n",
    "    C = A*B\n",
    "    \n",
    "    #forward\n",
    "    C_dot = A_dot*B + A*B_dot\n",
    "    \n",
    "    #adjoint\n",
    "    A_bar = C_bar*B.T\n",
    "    B_bar = A.T*C_bar\n",
    "    \n",
    "    #validation\n",
    "    LHS = np.trace(A_bar.T*A_dot + B_bar.T*B_dot)\n",
    "    RHS = np.trace(C_bar.T*C_dot)\n",
    "    print(LHS,RHS,f'error:{abs(LHS-RHS)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f01e9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.5191489014569166 -1.5191489014569164 error:2.220446049250313e-16\n"
     ]
    }
   ],
   "source": [
    "A = np.random.randint(0, 3, size=(4, 4))\n",
    "B = np.random.randint(1, 5, size=(4, 4))\n",
    "A_dot = np.random.randn(4,4)\n",
    "B_dot = np.random.randn(4,4)\n",
    "C_bar = np.random.randn(4,4)\n",
    "test_3(A,B,A_dot,B_dot,C_bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cca6ba9",
   "metadata": {},
   "source": [
    "# JAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b83a3c5",
   "metadata": {},
   "source": [
    "## testing with g as our object function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c454f498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient with respect to a: 0.234375\n",
      "Gradient with respect to b: -0.046875\n",
      "Gradient with respect to c: 0.03125\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def output(a, b, c):\n",
    "    d = b + c\n",
    "    e = a * c\n",
    "    f = d + e\n",
    "    g = e / f\n",
    "    return g  # Return only g because we're interested in gradients of g\n",
    "\n",
    "# Suppose we want the gradient of g with respect to a\n",
    "grad_g_wrt_a = jax.grad(output, argnums=0)\n",
    "\n",
    "# Suppose we want the gradient of g with respect to b\n",
    "grad_g_wrt_b = jax.grad(output, argnums=1)\n",
    "\n",
    "# Suppose we want the gradient of g with respect to c\n",
    "grad_g_wrt_c = jax.grad(output, argnums=2)\n",
    "\n",
    "# To compute the gradients, we need to provide actual input values\n",
    "a, b, c = 1.0, 2.0, 3.0  # Example values, these can be changed as needed\n",
    "\n",
    "# Calculate the gradients\n",
    "gradient_wrt_a = grad_g_wrt_a(a, b, c)\n",
    "gradient_wrt_b = grad_g_wrt_b(a, b, c)\n",
    "gradient_wrt_c = grad_g_wrt_c(a, b, c)\n",
    "\n",
    "# Print the results\n",
    "print('Gradient with respect to a:', gradient_wrt_a)\n",
    "print('Gradient with respect to b:', gradient_wrt_b)\n",
    "print('Gradient with respect to c:', gradient_wrt_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11e782c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient with respect to a: 874141000000.0\n",
      "Gradient with respect to b: 79467364000.0\n",
      "Gradient with respect to c: 370847700000.0\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "def output(a, b, c):\n",
    "    d = b+c\n",
    "    e= a*c\n",
    "    f= d+e\n",
    "    g = f*e\n",
    "    e = jnp.exp(g)\n",
    "    g += e\n",
    "    return g\n",
    "    \n",
    "\n",
    "grad_g_wrt_a = jax.grad(output, argnums=0)\n",
    "grad_g_wrt_b = jax.grad(output, argnums=1)\n",
    "grad_g_wrt_c = jax.grad(output, argnums=2)\n",
    "\n",
    "a, b, c = 1.0, 2.0, 3.0  \n",
    "\n",
    "gradient_wrt_a = grad_g_wrt_a(a, b, c)\n",
    "gradient_wrt_b = grad_g_wrt_b(a, b, c)\n",
    "gradient_wrt_c = grad_g_wrt_c(a, b, c)\n",
    "\n",
    "print('Gradient with respect to a:', gradient_wrt_a)\n",
    "print('Gradient with respect to b:', gradient_wrt_b)\n",
    "print('Gradient with respect to c:', gradient_wrt_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3456d98",
   "metadata": {},
   "source": [
    "## jax version case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05e5e5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHS: 0.11555557\n",
      "RHS: 0.11555557\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "#test_1_JAX\n",
    "# Define the function\n",
    "def f(a, b, c):\n",
    "    d = b + c\n",
    "    e = a * c\n",
    "    f = d + e\n",
    "    g = e / f\n",
    "    return g\n",
    "\n",
    "# Forward mode AD to get the tangents (derivatives of the output w.r.t. an input perturbation)\n",
    "a, b, c = 2.0, 3.0, 4.0  # Example input values\n",
    "a_dot, b_dot, c_dot = 1.0, 1.0, 1.0  # Example perturbations\n",
    "\n",
    "from jax import jacfwd\n",
    "forward_jacobian = jacfwd(f, (0, 1, 2))\n",
    "g_dot = forward_jacobian(a, b, c)\n",
    "g_dot = (g_dot[0] * a_dot + g_dot[1] * b_dot + g_dot[2] * c_dot)\n",
    "\n",
    "# Reverse mode AD to get the gradients (how the output changes w.r.t. each input)\n",
    "g_bar = 1.0  # The seed for the reverse mode is typically set to 1\n",
    "from jax import grad\n",
    "a_bar = grad(f, 0)(a, b, c) * g_bar\n",
    "b_bar = grad(f, 1)(a, b, c) * g_bar\n",
    "c_bar = grad(f, 2)(a, b, c) * g_bar\n",
    "\n",
    "# Validate that the dot products match\n",
    "lhs = a_dot * a_bar + b_dot * b_bar + c_dot * c_bar\n",
    "rhs = g_dot * g_bar\n",
    "\n",
    "print(\"LHS:\", lhs)\n",
    "print(\"RHS:\", rhs)\n",
    "assert jnp.isclose(lhs, rhs), \"Validation failed: LHS and RHS do not match!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9cc50",
   "metadata": {},
   "source": [
    "## jax version of case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "774b856c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHS: 1324456100000.0\n",
      "RHS: 1324456100000.0\n"
     ]
    }
   ],
   "source": [
    "#test_2_JAX\n",
    "# Define the function\n",
    "def f(a, b, c):\n",
    "    d = b+c\n",
    "    e= a*c\n",
    "    e_ = e\n",
    "    f= d+e\n",
    "    g = f*e\n",
    "    e = jnp.exp(g)\n",
    "    g += e\n",
    "    return g\n",
    "\n",
    "# Forward mode AD to get the tangents (derivatives of the output w.r.t. an input perturbation)\n",
    "a, b, c = 1.0, 2.0, 3.0  # Example input values\n",
    "a_dot, b_dot, c_dot = 1.0, 1.0, 1.0  # Example perturbations\n",
    "\n",
    "from jax import jacfwd\n",
    "forward_jacobian = jacfwd(f, (0, 1, 2))\n",
    "g_dot = forward_jacobian(a, b, c)\n",
    "g_dot = (g_dot[0] * a_dot + g_dot[1] * b_dot + g_dot[2] * c_dot)\n",
    "\n",
    "# Reverse mode AD to get the gradients (how the output changes w.r.t. each input)\n",
    "g_bar = 1.0  # The seed for the reverse mode is typically set to 1\n",
    "from jax import grad\n",
    "a_bar = grad(f, 0)(a, b, c) * g_bar\n",
    "b_bar = grad(f, 1)(a, b, c) * g_bar\n",
    "c_bar = grad(f, 2)(a, b, c) * g_bar\n",
    "\n",
    "# Validate that the dot products match\n",
    "lhs = a_dot * a_bar + b_dot * b_bar + c_dot * c_bar\n",
    "rhs = g_dot * g_bar\n",
    "\n",
    "print(\"LHS:\", lhs)\n",
    "print(\"RHS:\", rhs)\n",
    "assert jnp.isclose(lhs, rhs), \"Validation failed: LHS and RHS do not match!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e24c32",
   "metadata": {},
   "source": [
    "## jax in matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e599fe0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\n",
      "[[19. 22.]\n",
      " [43. 50.]]\n",
      "Gradient with respect to A:\n",
      "[[11. 15.]\n",
      " [11. 15.]]\n",
      "Gradient with respect to B:\n",
      "[[4. 4.]\n",
      " [6. 6.]]\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad\n",
    "\n",
    "def matrix_multiply(A, B):\n",
    "    return jnp.dot(A, B)\n",
    "\n",
    "A = jnp.array([[1.0, 2.0], [3.0, 4.0]])\n",
    "B = jnp.array([[5.0, 6.0], [7.0, 8.0]])\n",
    "\n",
    "C = matrix_multiply(A, B)\n",
    "\n",
    "def loss_function(A, B):\n",
    "    C = matrix_multiply(A, B)\n",
    "    return jnp.sum(C)\n",
    "\n",
    "grad_loss_wrt_A = grad(loss_function, argnums=0)(A, B)\n",
    "grad_loss_wrt_B = grad(loss_function, argnums=1)(A, B)\n",
    "\n",
    "print(\"C:\")\n",
    "print(C)\n",
    "\n",
    "print(\"Gradient with respect to A:\")\n",
    "print(grad_loss_wrt_A)\n",
    "\n",
    "print(\"Gradient with respect to B:\")\n",
    "print(grad_loss_wrt_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc58f58",
   "metadata": {},
   "source": [
    "## jax version of case 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f15a51cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LHS: 1.9607668\n",
      "RHS: 1.9607666\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Initialize random matrices for A and B\n",
    "key = jax.random.PRNGKey(0)\n",
    "A = jax.random.normal(key, (3, 3))\n",
    "B = jax.random.normal(key, (3, 3))\n",
    "\n",
    "# Define the matrix multiplication function\n",
    "def matmul(A, B):\n",
    "    return A @ B\n",
    "\n",
    "# Perform reverse mode AD to get A_bar and B_bar\n",
    "C_bar = jax.random.normal(key, (3, 3))\n",
    "_, vjp_fun = jax.vjp(matmul, A, B)  # vjp_fun now holds the gradient functions\n",
    "A_bar, B_bar = vjp_fun(C_bar)  # Call it with C_bar to get the gradients\n",
    "\n",
    "# Perform forward mode AD to get A_dot and B_dot\n",
    "A_dot = jax.random.normal(key, (3, 3))\n",
    "B_dot = jax.random.normal(key, (3, 3))\n",
    "_, C_dot = jax.jvp(matmul, (A, B), (A_dot, B_dot))\n",
    "\n",
    "# Validate the trace relationship\n",
    "lhs = jnp.trace(A_bar.T @ A_dot) + jnp.trace(B_bar.T @ B_dot)\n",
    "rhs = jnp.trace(C_bar.T @ C_dot)\n",
    "\n",
    "print('LHS:', lhs)\n",
    "print('RHS:', rhs)\n",
    "assert jnp.isclose(lhs, rhs), \"Validation failed: LHS and RHS do not match!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df78ce55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
